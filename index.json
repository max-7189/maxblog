[{"categories":["Projects","Mobile Development"],"content":"TeaInventory: Beverage Shop Inventory Management System - Technical Documentation ","date":"2025-04-03","objectID":"/maxblog/tea-inventory-system/:0:0","tags":["iOS","Swift","CoreData","Machine Learning","Inventory Management"],"title":"TeaInventory - Beverage Shop Inventory Management System","uri":"/maxblog/tea-inventory-system/"},{"categories":["Projects","Mobile Development"],"content":"1. Project Overview TeaInventory is an iOS inventory management system specifically designed for beverage shops, developed using SwiftUI and CoreData. It addresses key challenges in inventory management, ingredient consumption prediction, and intelligent restocking for tea shops. The project implements the MVVM architecture combined with machine learning technology to achieve intelligent inventory management. ","date":"2025-04-03","objectID":"/maxblog/tea-inventory-system/:1:0","tags":["iOS","Swift","CoreData","Machine Learning","Inventory Management"],"title":"TeaInventory - Beverage Shop Inventory Management System","uri":"/maxblog/tea-inventory-system/"},{"categories":["Projects","Mobile Development"],"content":"2. Technical Architecture ","date":"2025-04-03","objectID":"/maxblog/tea-inventory-system/:2:0","tags":["iOS","Swift","CoreData","Machine Learning","Inventory Management"],"title":"TeaInventory - Beverage Shop Inventory Management System","uri":"/maxblog/tea-inventory-system/"},{"categories":["Projects","Mobile Development"],"content":"2.1 Development Environment Language: Swift 5.9+ UI Framework: SwiftUI Data Persistence: CoreData Charts: SwiftUI Charts Minimum iOS Version: iOS 16.0 ","date":"2025-04-03","objectID":"/maxblog/tea-inventory-system/:2:1","tags":["iOS","Swift","CoreData","Machine Learning","Inventory Management"],"title":"TeaInventory - Beverage Shop Inventory Management System","uri":"/maxblog/tea-inventory-system/"},{"categories":["Projects","Mobile Development"],"content":"2.2 Architecture Design The project uses the MVVM (Model-View-ViewModel) architecture: Model: CoreData entities and business logic classes View: SwiftUI view layer ViewModel: Logic controllers, such as InventoryManager ","date":"2025-04-03","objectID":"/maxblog/tea-inventory-system/:2:2","tags":["iOS","Swift","CoreData","Machine Learning","Inventory Management"],"title":"TeaInventory - Beverage Shop Inventory Management System","uri":"/maxblog/tea-inventory-system/"},{"categories":["Projects","Mobile Development"],"content":"3. Core Data Models The project uses CoreData to design the following main entities: Ingredient: Contains attributes like name, category, currentStock, initialStock, price, leadTime, etc. Product: Contains name, price, isActive attributes and associations with RecipeItem and SalesRecord RecipeItem: Intermediate entity connecting Product and Ingredient SalesRecord: Records product sales data RestockRecord: Records ingredient restocking history InventoryCount: Records inventory counting data ","date":"2025-04-03","objectID":"/maxblog/tea-inventory-system/:3:0","tags":["iOS","Swift","CoreData","Machine Learning","Inventory Management"],"title":"TeaInventory - Beverage Shop Inventory Management System","uri":"/maxblog/tea-inventory-system/"},{"categories":["Projects","Mobile Development"],"content":"4. Core Functional Modules ","date":"2025-04-03","objectID":"/maxblog/tea-inventory-system/:4:0","tags":["iOS","Swift","CoreData","Machine Learning","Inventory Management"],"title":"TeaInventory - Beverage Shop Inventory Management System","uri":"/maxblog/tea-inventory-system/"},{"categories":["Projects","Mobile Development"],"content":"4.1 Ingredient Management (IngredientView) Ingredient CRUD operations Category management and filtering Detailed information display and editing Inventory status visualization (red-yellow-green indicators) Ingredient deletion functionality (with cascading deletion of related records) ","date":"2025-04-03","objectID":"/maxblog/tea-inventory-system/:4:1","tags":["iOS","Swift","CoreData","Machine Learning","Inventory Management"],"title":"TeaInventory - Beverage Shop Inventory Management System","uri":"/maxblog/tea-inventory-system/"},{"categories":["Projects","Mobile Development"],"content":"4.2 Product Management (ProductView) Product CRUD operations Recipe editing Sales records Product detail view Product deletion functionality (clearing related recipes and sales records) ","date":"2025-04-03","objectID":"/maxblog/tea-inventory-system/:4:2","tags":["iOS","Swift","CoreData","Machine Learning","Inventory Management"],"title":"TeaInventory - Beverage Shop Inventory Management System","uri":"/maxblog/tea-inventory-system/"},{"categories":["Projects","Mobile Development"],"content":"4.3 Inventory Count (InventoryCountView) Real-time inventory counting Count history records Calculation of actual consumption based on count differences Batch counting functionality (renamed to “Inventory Adjustment”) ","date":"2025-04-03","objectID":"/maxblog/tea-inventory-system/:4:3","tags":["iOS","Swift","CoreData","Machine Learning","Inventory Management"],"title":"TeaInventory - Beverage Shop Inventory Management System","uri":"/maxblog/tea-inventory-system/"},{"categories":["Projects","Mobile Development"],"content":"4.4 Restock Management (RestockRecordView) Intelligent restocking suggestions Restock record management One-click restocking functionality Restock quantity calculation based on dynamic safety stock ","date":"2025-04-03","objectID":"/maxblog/tea-inventory-system/:4:4","tags":["iOS","Swift","CoreData","Machine Learning","Inventory Management"],"title":"TeaInventory - Beverage Shop Inventory Management System","uri":"/maxblog/tea-inventory-system/"},{"categories":["Projects","Mobile Development"],"content":"4.5 Data Analysis (AnalyticsView) Sales trend analysis Ingredient consumption analysis Chart visualization ","date":"2025-04-03","objectID":"/maxblog/tea-inventory-system/:4:5","tags":["iOS","Swift","CoreData","Machine Learning","Inventory Management"],"title":"TeaInventory - Beverage Shop Inventory Management System","uri":"/maxblog/tea-inventory-system/"},{"categories":["Projects","Mobile Development"],"content":"4.6 Settings Management (SettingsView) Feature toggle controls Prediction model parameter adjustments Regression model parameter adjustments Data import/export System reset functionality ","date":"2025-04-03","objectID":"/maxblog/tea-inventory-system/:4:6","tags":["iOS","Swift","CoreData","Machine Learning","Inventory Management"],"title":"TeaInventory - Beverage Shop Inventory Management System","uri":"/maxblog/tea-inventory-system/"},{"categories":["Projects","Mobile Development"],"content":"5. Intelligent Prediction System ","date":"2025-04-03","objectID":"/maxblog/tea-inventory-system/:5:0","tags":["iOS","Swift","CoreData","Machine Learning","Inventory Management"],"title":"TeaInventory - Beverage Shop Inventory Management System","uri":"/maxblog/tea-inventory-system/"},{"categories":["Projects","Mobile Development"],"content":"5.1 Basic Prediction Model: Dynamic Safety Stock Calculation 5.1.1 Mathematical Principles The basic prediction model is primarily based on dynamic safety stock theory, using exponential smoothing and service level concepts to optimize inventory management. The core formula for safety stock calculation is: $$SS = z \\cdot \\sigma_L \\cdot \\sqrt{L}$$ Where: $SS$ is the safety stock level $z$ is the Z-score corresponding to the service level in standard normal distribution $\\sigma_L$ is the standard deviation of demand $L$ is the lead time for restocking In the system implementation, it is expressed as: $$SS = \\overline{D} \\cdot L + z \\cdot \\sigma_D \\cdot \\sqrt{L}$$ Where: $\\overline{D}$ is the daily average consumption $\\sigma_D$ is the standard deviation of consumption 5.1.2 Service Level and Z-Score Relationship Service levels and Z-scores are related through the standard normal distribution function: Service Level Z-Score 90% 1.28 95% 1.65 98% 2.33 99% 2.58 5.1.3 Exponential Smoothing Exponential smoothing is used to predict future consumption, calculated as: $$F_t = \\alpha \\cdot D_{t-1} + (1-\\alpha) \\cdot F_{t-1}$$ Where: $F_t$ is the forecast for time t $D_{t-1}$ is the actual consumption at time t-1 $F_{t-1}$ is the forecast for time t-1 $\\alpha$ is the smoothing coefficient (0.1-0.5) ","date":"2025-04-03","objectID":"/maxblog/tea-inventory-system/:5:1","tags":["iOS","Swift","CoreData","Machine Learning","Inventory Management"],"title":"TeaInventory - Beverage Shop Inventory Management System","uri":"/maxblog/tea-inventory-system/"},{"categories":["Projects","Mobile Development"],"content":"5.1.4 Code Implementation func calculateDynamicSafetyStock(ingredient: Ingredient, alpha: Double? = nil, serviceLevel: Double? = nil) -\u003e Double { // If prediction feature is turned off, return a percentage of initial stock as safety stock if !enablePrediction { return ingredient.initialStock * 0.2 } let serviceLevelValue = serviceLevel ?? self.serviceLevel let dailyConsumptionAverage = calculateDailyConsumptionAverage(ingredient: ingredient) let standardDeviation = calculateConsumptionStandardDeviation(ingredient: ingredient) let leadTime = Double(ingredient.leadTime) // Service level coefficient (Z) let zScore = calculateZScore(serviceLevel: serviceLevelValue) return dailyConsumptionAverage * leadTime + zScore * standardDeviation * sqrt(leadTime) } // Z-score calculation private func calculateZScore(serviceLevel: Double) -\u003e Double { switch serviceLevel { case 0.90...0.91: return 1.28 case 0.92...0.93: return 1.41 case 0.94...0.95: return 1.65 case 0.96...0.97: return 1.88 case 0.98...0.99: return 2.33 case 0.9985...0.9999: return 3.0 default: return 1.65 } } // Standard deviation calculation private func calculateStandardDeviation(values: [Double]) -\u003e Double { guard !values.isEmpty else { return 0.0 } let count = Double(values.count) let mean = values.reduce(0.0, +) / count let sumOfSquaredDifferences = values.map { pow($0 - mean, 2) }.reduce(0.0, +) return sqrt(sumOfSquaredDifferences / count) } ","date":"2025-04-03","objectID":"/maxblog/tea-inventory-system/:5:2","tags":["iOS","Swift","CoreData","Machine Learning","Inventory Management"],"title":"TeaInventory - Beverage Shop Inventory Management System","uri":"/maxblog/tea-inventory-system/"},{"categories":["Projects","Mobile Development"],"content":"5.1.5 Reorder Point and Restock Quantity Calculation The system determines whether restocking is needed based on current inventory and safety stock: $$RestockQuantity = (DailyConsumptionAverage \\times LeadTime + SafetyStock) - CurrentStock$$ This is implemented in code as: func calculateSuggestedRestockAmount(ingredient: Ingredient) -\u003e Double { let remainingStock = calculateRemainingStock(ingredient: ingredient) if enablePrediction { let dailyConsumptionAverage = calculateDailyConsumptionAverage(ingredient: ingredient) let leadTime = Double(ingredient.leadTime) // Calculate expected consumption during lead time let expectedConsumptionDuringLeadTime = dailyConsumptionAverage * leadTime // Calculate safety stock let safetyStock = calculateDynamicSafetyStock(ingredient: ingredient) // Suggested restock amount = Expected consumption during lead time + Safety stock - Current stock let suggestedAmount = expectedConsumptionDuringLeadTime + safetyStock - remainingStock return max(0, suggestedAmount) } else { return max(0, ingredient.initialStock - remainingStock) } } ","date":"2025-04-03","objectID":"/maxblog/tea-inventory-system/:5:3","tags":["iOS","Swift","CoreData","Machine Learning","Inventory Management"],"title":"TeaInventory - Beverage Shop Inventory Management System","uri":"/maxblog/tea-inventory-system/"},{"categories":["Projects","Mobile Development"],"content":"5.2 Regression Analysis Model: Ingredient Consumption Prediction 5.2.1 Mathematical Principles The regression analysis model uses multivariate linear regression techniques to establish the relationship between product sales and ingredient consumption. The core is solving the matrix equation: $$\\mathbf{y} = \\mathbf{X}\\mathbf{\\beta} + \\mathbf{\\epsilon}$$ Where: $\\mathbf{y}$ is the ingredient consumption vector $\\mathbf{X}$ is the product sales matrix $\\mathbf{\\beta}$ is the regression coefficient vector (to be determined) $\\mathbf{\\epsilon}$ is the error term The system implements linear regression with L2 regularization (Ridge regression), with the objective function: $$J(\\mathbf{\\beta}) = \\frac{1}{2m}\\sum_{i=1}^{m}(h_{\\mathbf{\\beta}}(\\mathbf{x}^{(i)}) - y^{(i)})^2 + \\frac{\\lambda}{2m}\\sum_{j=1}^{n}\\beta_j^2$$ Where: $m$ is the number of samples $n$ is the number of features (product types) $\\lambda$ is the regularization parameter $h_{\\mathbf{\\beta}}(\\mathbf{x}^{(i)})$ is the prediction function, equal to $\\mathbf{x}^{(i)} \\cdot \\mathbf{\\beta}$ 5.2.2 Hybrid Prediction System The final prediction uses a hybrid system, combining recipe calculation and regression prediction: $$Consumption = \\alpha \\times RecipeCalculatedValue + (1-\\alpha) \\times RegressionPredictedValue$$ Where $\\alpha$ is adjusted with model maturity: $$\\alpha = 1 - ModelMaturity$$ 5.2.3 Gradient Descent Training // Train model using gradient descent algorithm private func trainWithGradientDescent(X: [[Double]], y: [Double], iterations: Int = 1000, learningRate: Double = 0.01, l2Regularization: Double = 0.1) -\u003e [Double] { let m = Double(X.count) // Number of samples let n = X[0].count // Number of features // Initialize parameters var theta = Array(repeating: 0.0, n) // Execute gradient descent for _ in 0..\u003citerations { // Calculate predictions let predictions = X.map { row in dotProduct(row, theta) } // Calculate errors let errors = zip(predictions, y).map { $0 - $1 } // Update parameters (with L2 regularization) for j in 0..\u003cn { let gradient = (1.0/m) * ( zip(errors, X).map { error, row in error * row[j] }.reduce(0, +) + l2Regularization * theta[j] // L2 regularization term ) theta[j] = theta[j] - learningRate * gradient } } return theta } // Calculate dot product private func dotProduct(_ row: [Double], _ theta: [Double]) -\u003e Double { return zip(row, theta).reduce(0.0) { $0 + $1.0 * $1.1 } } 5.2.4 Feature Normalization // Normalize features private func normalizeFeatures(X: [[Double]]) -\u003e ([[Double]], [Double], [Double]) { let n = X[0].count var means = Array(repeating: 0.0, count: n) var stdDevs = Array(repeating: 0.0, count: n) // Calculate mean for each column for j in 0..\u003cn { let column = X.map { $0[j] } means[j] = column.reduce(0.0, +) / Double(column.count) } // Calculate standard deviation for each column for j in 0..\u003cn { let column = X.map { $0[j] } let squaredDiffs = column.map { pow($0 - means[j], 2) } stdDevs[j] = sqrt(squaredDiffs.reduce(0.0, +) / Double(column.count)) // Prevent division by zero if stdDevs[j] == 0 { stdDevs[j] = 1.0 } } // Normalize data let normalizedX = X.map { row in (0..\u003cn).map { j in (row[j] - means[j]) / stdDevs[j] } } return (normalizedX, means, stdDevs) } 5.2.5 Hybrid Prediction Implementation // Predict consumption func predictConsumption(ingredientID: String, sales: [String: Double], recipeBasedConsumption: Double) -\u003e Double { // Get hybrid coefficient let alpha = RegressionModelStore.shared.getModelAlpha() // Recipe-based calculation let recipeAmount = recipeBasedConsumption // If no trained model or empty sales data, return recipe-based calculation guard let model = models[ingredientID], !sales.isEmpty else { return recipeAmount } // Prepare feature vector var features: [Double] = [] for productID in model.productIDs { features.append(sales[productID] ?? 0.0) } // Feature normalization let normalizedFeatures = features.enumerated().map { j, value in (value - model.means[j]) / model.stdDevs[j] } // Calculate prediction ","date":"2025-04-03","objectID":"/maxblog/tea-inventory-system/:5:4","tags":["iOS","Swift","CoreData","Machine Learning","Inventory Management"],"title":"TeaInventory - Beverage Shop Inventory Management System","uri":"/maxblog/tea-inventory-system/"},{"categories":["Projects","Mobile Development"],"content":"5.3 Model Integration and Adaptive Mechanisms The Tea system integrates the two models and implements adaptive optimization through the following mechanisms: Data Collection: Collecting actual consumption data through inventory count differences and sales records Model Training Triggers: Early versions: New data automatically triggers training Current version: Manual confirmation of training to ensure high-quality data Adaptive Adjustment of Hybrid Coefficients: As model maturity increases, α value automatically decreases Users can manually adjust to accommodate recipe changes Prediction Evaluation: Using Mean Squared Error (MSE) to evaluate model performance Normalized scoring by comparison with benchmark models This integrated design combines classical inventory theory with machine learning methods to achieve efficient and accurate inventory prediction and management, particularly suitable for beverage shops with complex recipes and variable consumption patterns. ","date":"2025-04-03","objectID":"/maxblog/tea-inventory-system/:5:5","tags":["iOS","Swift","CoreData","Machine Learning","Inventory Management"],"title":"TeaInventory - Beverage Shop Inventory Management System","uri":"/maxblog/tea-inventory-system/"},{"categories":["Projects","Mobile Development"],"content":"6. Technical Highlights ","date":"2025-04-03","objectID":"/maxblog/tea-inventory-system/:6:0","tags":["iOS","Swift","CoreData","Machine Learning","Inventory Management"],"title":"TeaInventory - Beverage Shop Inventory Management System","uri":"/maxblog/tea-inventory-system/"},{"categories":["Projects","Mobile Development"],"content":"6.1 Optimized CoreData Usage Batch deletion operations (NSBatchDeleteRequest) Well-designed relationship models Cascading deletion implementation ","date":"2025-04-03","objectID":"/maxblog/tea-inventory-system/:6:1","tags":["iOS","Swift","CoreData","Machine Learning","Inventory Management"],"title":"TeaInventory - Beverage Shop Inventory Management System","uri":"/maxblog/tea-inventory-system/"},{"categories":["Projects","Mobile Development"],"content":"6.2 Advanced SwiftUI Features Custom Alert and Sheet interactions Complex form design Dynamic lists and filtering Multi-level navigation structure Conditional rendering and state management ","date":"2025-04-03","objectID":"/maxblog/tea-inventory-system/:6:2","tags":["iOS","Swift","CoreData","Machine Learning","Inventory Management"],"title":"TeaInventory - Beverage Shop Inventory Management System","uri":"/maxblog/tea-inventory-system/"},{"categories":["Projects","Mobile Development"],"content":"6.3 Advanced Error Prevention Mechanisms Multi-layer confirmation dialogs Text validation mechanisms Clear UI feedback for states ","date":"2025-04-03","objectID":"/maxblog/tea-inventory-system/:6:3","tags":["iOS","Swift","CoreData","Machine Learning","Inventory Management"],"title":"TeaInventory - Beverage Shop Inventory Management System","uri":"/maxblog/tea-inventory-system/"},{"categories":["Projects","Mobile Development"],"content":"6.4 Data Analysis and Visualization Trend charts Inventory status visualization Intelligent restocking suggestions ","date":"2025-04-03","objectID":"/maxblog/tea-inventory-system/:6:4","tags":["iOS","Swift","CoreData","Machine Learning","Inventory Management"],"title":"TeaInventory - Beverage Shop Inventory Management System","uri":"/maxblog/tea-inventory-system/"},{"categories":["Projects","Mobile Development"],"content":"6.5 Google Sheets Integration Cloud data synchronization via GoogleSheetsManager Support for various operation logs ","date":"2025-04-03","objectID":"/maxblog/tea-inventory-system/:6:5","tags":["iOS","Swift","CoreData","Machine Learning","Inventory Management"],"title":"TeaInventory - Beverage Shop Inventory Management System","uri":"/maxblog/tea-inventory-system/"},{"categories":["Projects","Mobile Development"],"content":"7. Security Features Sensitive operations (such as deletion and reset) require multiple confirmations Data validation and error handling Operation logging ","date":"2025-04-03","objectID":"/maxblog/tea-inventory-system/:7:0","tags":["iOS","Swift","CoreData","Machine Learning","Inventory Management"],"title":"TeaInventory - Beverage Shop Inventory Management System","uri":"/maxblog/tea-inventory-system/"},{"categories":["Projects","Mobile Development"],"content":"8. Extensibility Design The system adopts a modular design for easy extension of new features: Reserved data import/export interfaces Configurable prediction parameters Customizable UI components Loosely coupled business logic ","date":"2025-04-03","objectID":"/maxblog/tea-inventory-system/:8:0","tags":["iOS","Swift","CoreData","Machine Learning","Inventory Management"],"title":"TeaInventory - Beverage Shop Inventory Management System","uri":"/maxblog/tea-inventory-system/"},{"categories":["Projects","Mobile Development"],"content":"9. Future Development Directions Further optimization of regression model algorithms Addition of more data analysis features Implementation of complete data import/export functionality Support for multi-user collaboration and permission management Enhanced integration with external systems (such as POS) The TeaInventory system significantly improves beverage shop inventory management efficiency through advanced prediction algorithms and intuitive user interfaces, reducing inventory waste and optimizing the restocking process, representing the latest level of inventory management technology in the industry. ","date":"2025-04-03","objectID":"/maxblog/tea-inventory-system/:9:0","tags":["iOS","Swift","CoreData","Machine Learning","Inventory Management"],"title":"TeaInventory - Beverage Shop Inventory Management System","uri":"/maxblog/tea-inventory-system/"},{"categories":["Projects","AI Research"],"content":"DataMuse Project: In-Depth Analysis ","date":"2025-03-25","objectID":"/maxblog/datamuse-project/:0:0","tags":["AI","AGI","AutoGen","Multi-Agent Systems","Python","Electron"],"title":"DataMuse Project: A Multi-Agent AI System","uri":"/maxblog/datamuse-project/"},{"categories":["Projects","AI Research"],"content":"Project Origins Before developing DataMuse, I had attempted to create a project called saasBI. During my research into the core architecture of multi-agent systems, I encountered numerous challenges: imperfect agent collaboration mechanisms, difficulties in context management, and a lack of standardized tool integration. These challenges prompted me to explore mature open-source frameworks. AutoGen (AG2) caught my attention with its flexible architecture and rich functionality. I decided to build a more specialized and user-friendly multi-agent application based on AG2, which became the origin of DataMuse. ","date":"2025-03-25","objectID":"/maxblog/datamuse-project/:1:0","tags":["AI","AGI","AutoGen","Multi-Agent Systems","Python","Electron"],"title":"DataMuse Project: A Multi-Agent AI System","uri":"/maxblog/datamuse-project/"},{"categories":["Projects","AI Research"],"content":"Project Overview DataMuse is a multi-agent artificial general intelligence (AGI) application built on AutoGen 0.8.6. It provides an AGI-like experience by integrating various specialized agents—such as researchers, programmers, planners, and others—that work collaboratively to solve complex problems. ","date":"2025-03-25","objectID":"/maxblog/datamuse-project/:2:0","tags":["AI","AGI","AutoGen","Multi-Agent Systems","Python","Electron"],"title":"DataMuse Project: A Multi-Agent AI System","uri":"/maxblog/datamuse-project/"},{"categories":["Projects","AI Research"],"content":"Technical Architecture DataMuse adopts a layered architectural design, primarily divided into the following components: Core Agent Layer: Various specialized agents implemented based on AG2 Tool Integration Layer: Provides functional tools such as web search and file operations Configuration Management Layer: Unified configuration interface supporting different LLMs and execution environments UI Interaction Layer: Cross-platform desktop interface based on Electron Communication Layer: WebSocket server for real-time communication between frontend and backend ","date":"2025-03-25","objectID":"/maxblog/datamuse-project/:3:0","tags":["AI","AGI","AutoGen","Multi-Agent Systems","Python","Electron"],"title":"DataMuse Project: A Multi-Agent AI System","uri":"/maxblog/datamuse-project/"},{"categories":["Projects","AI Research"],"content":"File Structure datamuse/ ├── agents/ # Agent definitions and factory functions ├── config/ # Configuration management ├── examples/ # Example programs ├── tools/ # Tools and utilities ├── utils/ # General utility classes ├── datamuse-electron/ # Frontend interface ├── main.py # Main program entry ├── ws_server.py # WebSocket server └── start_ws_server.py # Startup script ","date":"2025-03-25","objectID":"/maxblog/datamuse-project/:3:1","tags":["AI","AGI","AutoGen","Multi-Agent Systems","Python","Electron"],"title":"DataMuse Project: A Multi-Agent AI System","uri":"/maxblog/datamuse-project/"},{"categories":["Projects","AI Research"],"content":"AG2 Core Principles Analysis AutoGen (AG2) is a framework for building LLM applications that allows multiple AI agents to collaborate through conversation to complete tasks. Its core principles include: ","date":"2025-03-25","objectID":"/maxblog/datamuse-project/:4:0","tags":["AI","AGI","AutoGen","Multi-Agent Systems","Python","Electron"],"title":"DataMuse Project: A Multi-Agent AI System","uri":"/maxblog/datamuse-project/"},{"categories":["Projects","AI Research"],"content":"1. Agent Basic Architecture AG2’s agent system is based on a conversation-centered interaction model: ConversableAgent: Base class for all agents, providing message processing and conversation management capabilities AssistantAgent: LLM-driven assistant agent responsible for generating content and answering questions UserProxyAgent: Agent representing users, capable of executing code and interacting with users Each agent has its own memory system, which can remember conversation history and make decisions based on it. ","date":"2025-03-25","objectID":"/maxblog/datamuse-project/:4:1","tags":["AI","AGI","AutoGen","Multi-Agent Systems","Python","Electron"],"title":"DataMuse Project: A Multi-Agent AI System","uri":"/maxblog/datamuse-project/"},{"categories":["Projects","AI Research"],"content":"2. Multi-Agent Collaboration Mechanism AG2 implements multi-agent collaboration mainly through the following modes: One-on-One Conversation: Direct interaction between two agents, such as a user and an assistant GroupChat: Group chat mode where multiple agents collaborate in the same conversation space GroupChatManager: Group chat manager responsible for coordinating the interaction flow of multiple agents In DataMuse, I implemented several different working modes: class WorkMode(Enum): AUTO = \"auto\" # Automatically select the most appropriate mode INTERACTIVE = \"interactive\" # Interactive mode ASSISTED = \"assisted\" # Assisted mode ","date":"2025-03-25","objectID":"/maxblog/datamuse-project/:4:2","tags":["AI","AGI","AutoGen","Multi-Agent Systems","Python","Electron"],"title":"DataMuse Project: A Multi-Agent AI System","uri":"/maxblog/datamuse-project/"},{"categories":["Projects","AI Research"],"content":"3. Tool Calling Implementation The core mechanism of AG2’s tool calling is through function registration and calling framework: Function Registration: Register various tool functions to the agent Function Description: Each tool has metadata such as descriptions and parameter explanations Call Decision: The agent decides which tool to call based on task requirements Result Processing: Process tool execution results and continue the conversation This process is similar to OpenAI’s Function Calling mechanism, but AG2 provides more powerful integration capabilities. In the DataMuse project, I implemented various types of tools, such as: # Search tool implementation example def web_search(query: str) -\u003e str: \"\"\"Perform a web search and return results\"\"\" # Implement search logic return search_results ","date":"2025-03-25","objectID":"/maxblog/datamuse-project/:4:3","tags":["AI","AGI","AutoGen","Multi-Agent Systems","Python","Electron"],"title":"DataMuse Project: A Multi-Agent AI System","uri":"/maxblog/datamuse-project/"},{"categories":["Projects","AI Research"],"content":"Specialized Agents An important feature of the DataMuse project is its variety of specialized agents: Researcher: Focuses on collecting and analyzing information, excels at providing detailed factual materials Programmer: Focuses on writing high-quality code and solving technical problems Planner: Focuses on formulating strategies and action plans Critic: Focuses on reviewing and providing constructive feedback Executor: Focuses on executing code and commands to implement actual functionality Each agent has specific system prompts and behavior patterns: def create_programmer_agent(name: str = \"Programmer\", description: str = \"Focuses on writing high-quality code...\", llm_config = None): system_message = f\"\"\"You are {name}, an experienced programmer assistant. Your main responsibilities are: 1. Write clear, efficient, and maintainable code 2. Solve technical problems and debug errors 3. Optimize software performance and code quality 4. Provide detailed code explanations and documentation {description} \"\"\" return AssistantAgent(name=name, system_message=system_message, llm_config=llm_config) ","date":"2025-03-25","objectID":"/maxblog/datamuse-project/:5:0","tags":["AI","AGI","AutoGen","Multi-Agent Systems","Python","Electron"],"title":"DataMuse Project: A Multi-Agent AI System","uri":"/maxblog/datamuse-project/"},{"categories":["Projects","AI Research"],"content":"Team Collaboration Mode DataMuse implements various collaboration modes, the most important being the team collaboration mode. In this mode, multiple specialized agents work together to solve complex problems: async def run_team_chat(task: str): \"\"\"Run team collaboration dialogue\"\"\" # Create specialized agents planner = create_planner_agent(name=\"Planner\") programmer = create_programmer_agent(name=\"Programmer\") researcher = create_researcher_agent(name=\"Researcher\") critic = create_critic_agent(name=\"Critic\") executor = create_executor_agent(name=\"Executor\") # Create group chat group_chat = GroupChat( agents=[planner, programmer, researcher, critic, executor, user], max_round=20 ) manager = GroupChatManager(groupchat=group_chat, llm_config=llm_config) # Start group chat await user.a_initiate_chat(manager, message=task) ","date":"2025-03-25","objectID":"/maxblog/datamuse-project/:6:0","tags":["AI","AGI","AutoGen","Multi-Agent Systems","Python","Electron"],"title":"DataMuse Project: A Multi-Agent AI System","uri":"/maxblog/datamuse-project/"},{"categories":["Projects","AI Research"],"content":"Frontend-Backend Communication with WebSocket To provide a better user experience, DataMuse uses WebSocket for real-time communication between frontend and backend: async def start_server(host: str = \"127.0.0.1\", port: int = 8000): \"\"\"Start WebSocket server\"\"\" app = FastAPI() # Configure CORS app.add_middleware( CORSMiddleware, allow_origins=[\"*\"], allow_credentials=True, allow_methods=[\"*\"], allow_headers=[\"*\"], ) # Various routes and WebSocket handling logic # ... # Start server config = uvicorn.Config(app=app, host=host, port=port) server = uvicorn.Server(config) await server.serve() The frontend is built with Electron and React, communicating with the backend Python service through WebSocket, providing a real-time interactive experience. ","date":"2025-03-25","objectID":"/maxblog/datamuse-project/:7:0","tags":["AI","AGI","AutoGen","Multi-Agent Systems","Python","Electron"],"title":"DataMuse Project: A Multi-Agent AI System","uri":"/maxblog/datamuse-project/"},{"categories":["Projects","AI Research"],"content":"Future Outlook The DataMuse project continues to evolve, with future plans including: Enhancing collaboration capabilities between agents Expanding capabilities in more specialized domains Improving efficiency in solving complex tasks Further optimizing the user experience ","date":"2025-03-25","objectID":"/maxblog/datamuse-project/:8:0","tags":["AI","AGI","AutoGen","Multi-Agent Systems","Python","Electron"],"title":"DataMuse Project: A Multi-Agent AI System","uri":"/maxblog/datamuse-project/"},{"categories":["Projects","AI Research"],"content":"Conclusion The DataMuse project is a multi-agent AGI-like application based on AG2, solving complex problems through the collaboration of multiple specialized agents. It not only showcases the powerful functionality of the AG2 framework but also explores the potential applications of multi-agent collaboration in solving real-world problems. ","date":"2025-03-25","objectID":"/maxblog/datamuse-project/:9:0","tags":["AI","AGI","AutoGen","Multi-Agent Systems","Python","Electron"],"title":"DataMuse Project: A Multi-Agent AI System","uri":"/maxblog/datamuse-project/"},{"categories":["Projects","AI Research"],"content":"GraceAI Project - Bringing AI Companionship from Science Fiction to Reality ","date":"2025-02-15","objectID":"/maxblog/graceai-project/:0:0","tags":["AI","Machine Learning","iOS Development","NLP","AI Companions"],"title":"GraceAI Project - Bringing AI Companionship from Science Fiction to Reality","uri":"/maxblog/graceai-project/"},{"categories":["Projects","AI Research"],"content":"1. Project Background and Inspiration ","date":"2025-02-15","objectID":"/maxblog/graceai-project/:1:0","tags":["AI","Machine Learning","iOS Development","NLP","AI Companions"],"title":"GraceAI Project - Bringing AI Companionship from Science Fiction to Reality","uri":"/maxblog/graceai-project/"},{"categories":["Projects","AI Research"],"content":"1.1 Insights from the Movie “Her” Spike Jonze’s “Her” (2013) portrays a near future where the protagonist Theodore falls in love with an operating system AI named Samantha. In the film, Samantha demonstrates profound emotional understanding, personality growth, and authentic communication abilities, which seemed like unattainable science fiction elements at the time. However, with the rapid advancement of large language model (LLM) technology in recent years, the human-machine emotional interactions depicted in the film have gradually moved from science fiction toward the edge of possibility. Progress in dialogue capabilities, memory integration, and personality expression from OpenAI’s GPT models, Anthropic’s Claude, and other advanced AI systems has made creating an AI companion with persistent memory and unique personality a feasible technical exploration direction. ","date":"2025-02-15","objectID":"/maxblog/graceai-project/:1:1","tags":["AI","Machine Learning","iOS Development","NLP","AI Companions"],"title":"GraceAI Project - Bringing AI Companionship from Science Fiction to Reality","uri":"/maxblog/graceai-project/"},{"categories":["Projects","AI Research"],"content":"1.2 The Journey from Science Fiction to Reality Ten years ago, the AI-human emotional connection presented in “Her” was merely a romantic science fiction imagination. As a technology enthusiast, I was deeply attracted to the concept in the film but also believed such technology would take decades to realize. With the explosive development of large language models in 2022-2023, I began to reconsider this question: If Theodore lived in 2024, could his story with Samantha already be technically feasible? This question prompted me to begin exploring the GraceAI project. I realized that modern LLMs already possess three key capabilities: Natural, fluent conversational abilities Memory and contextual understanding Presentation of specific personality traits through fine-tuning These technological breakthroughs not only make the scenarios depicted in “Her” technically feasible but also inspire deep reflection on the nature of AI emotional companionship: When AI can provide emotional resonance and understanding, what is the essence of this connection? ","date":"2025-02-15","objectID":"/maxblog/graceai-project/:1:2","tags":["AI","Machine Learning","iOS Development","NLP","AI Companions"],"title":"GraceAI Project - Bringing AI Companionship from Science Fiction to Reality","uri":"/maxblog/graceai-project/"},{"categories":["Projects","AI Research"],"content":"2. Project Overview and Objectives ","date":"2025-02-15","objectID":"/maxblog/graceai-project/:2:0","tags":["AI","Machine Learning","iOS Development","NLP","AI Companions"],"title":"GraceAI Project - Bringing AI Companionship from Science Fiction to Reality","uri":"/maxblog/graceai-project/"},{"categories":["Projects","AI Research"],"content":"2.1 Core Principles of GraceAI The GraceAI project aims to explore the technical boundaries of AI companionship, creating an AI system capable of establishing lasting, personalized emotional connections with users. Unlike general assistants, GraceAI focuses on: Long-term Memory and Growth: Ability to remember interaction history with users and develop relationships over time Personality Consistency: Displaying consistent personality traits and values Emotional Resonance: Ability to understand, respond to, and appropriately express emotions Natural Communication: Achieving seamless, natural conversational experiences through voice interaction ","date":"2025-02-15","objectID":"/maxblog/graceai-project/:2:1","tags":["AI","Machine Learning","iOS Development","NLP","AI Companions"],"title":"GraceAI Project - Bringing AI Companionship from Science Fiction to Reality","uri":"/maxblog/graceai-project/"},{"categories":["Projects","AI Research"],"content":"2.2 Technical Research Objectives The technical research objectives of this project include: Implementing a RAG-based long-term memory system enabling AI to remember past interactions Creating a unique and consistent AI personality through fine-tuning large language models Building a privacy-first iOS application architecture ensuring user data security Exploring best practices for natural voice interactions to create immersive experiences ","date":"2025-02-15","objectID":"/maxblog/graceai-project/:2:2","tags":["AI","Machine Learning","iOS Development","NLP","AI Companions"],"title":"GraceAI Project - Bringing AI Companionship from Science Fiction to Reality","uri":"/maxblog/graceai-project/"},{"categories":["Projects","AI Research"],"content":"2.3 Ethical Boundaries As an exploratory project, GraceAI recognizes the ethical complexity of the AI emotional companionship field. The project adheres to the following principles: Transparency: The AI always clearly indicates its non-human nature User Autonomy: Users maintain complete control over their interaction data Mental Health Considerations: Avoiding design features that might lead to unhealthy dependencies Research Orientation: Positioning the project as an exploration of technical possibilities rather than a commercial product ","date":"2025-02-15","objectID":"/maxblog/graceai-project/:2:3","tags":["AI","Machine Learning","iOS Development","NLP","AI Companions"],"title":"GraceAI Project - Bringing AI Companionship from Science Fiction to Reality","uri":"/maxblog/graceai-project/"},{"categories":["Projects","AI Research"],"content":"3. Technical Architecture Design ","date":"2025-02-15","objectID":"/maxblog/graceai-project/:3:0","tags":["AI","Machine Learning","iOS Development","NLP","AI Companions"],"title":"GraceAI Project - Bringing AI Companionship from Science Fiction to Reality","uri":"/maxblog/graceai-project/"},{"categories":["Projects","AI Research"],"content":"3.1 System Architecture Overview GraceAI employs a hybrid architectural design, balancing local processing with cloud service capabilities: ┌─────────────────────────────────────────────────────────┐ │ iOS App Layer │ │ ┌─────────────┐ ┌─────────────┐ ┌─────────────┐ │ │ │ User │ │ Local Memory│ │ Audio │ │ │ │ Interface │ │ Management │ │ Processing │ │ │ └─────────────┘ └─────────────┘ └─────────────┘ │ └────────────┬────────────────┬────────────────┬──────────┘ │ │ │ ┌────────────▼────────────────▼────────────────▼──────────┐ │ Integration Service Layer │ │ ┌─────────────┐ ┌─────────────┐ ┌─────────────┐ │ │ │ LLM API │ │ Vector │ │ STT/TTS │ │ │ │ Interface │ │ Database │ │ Services │ │ │ └─────────────┘ └─────────────┘ └─────────────┘ │ └────────────┬─────────────────────────────────┬──────────┘ │ │ ┌────────────▼───┐ ┌──────▼─────────┐ │ OpenAI API │ ───────────────────\u003e │ Voice Service │ │ │ │ APIs │ └────────────────┘ └────────────────┘ ","date":"2025-02-15","objectID":"/maxblog/graceai-project/:3:1","tags":["AI","Machine Learning","iOS Development","NLP","AI Companions"],"title":"GraceAI Project - Bringing AI Companionship from Science Fiction to Reality","uri":"/maxblog/graceai-project/"},{"categories":["Projects","AI Research"],"content":"3.2 Technology Stack Selection Frontend/Application Layer: Swift/SwiftUI (iOS native development) Core Data (local data storage) AVFoundation (audio processing) AI/Machine Learning: OpenAI GPT API (conversation generation) OpenAI Embedding API (text vectorization) SQLite + vector extension (local vector database) Backend/Cloud Services: iCloud (optional synchronization) OpenAI service calls based on API keys Fine-tuned model hosting (OpenAI platform) ","date":"2025-02-15","objectID":"/maxblog/graceai-project/:3:2","tags":["AI","Machine Learning","iOS Development","NLP","AI Companions"],"title":"GraceAI Project - Bringing AI Companionship from Science Fiction to Reality","uri":"/maxblog/graceai-project/"},{"categories":["Projects","AI Research"],"content":"4. RAG Long-term Memory System Detailed Design ","date":"2025-02-15","objectID":"/maxblog/graceai-project/:4:0","tags":["AI","Machine Learning","iOS Development","NLP","AI Companions"],"title":"GraceAI Project - Bringing AI Companionship from Science Fiction to Reality","uri":"/maxblog/graceai-project/"},{"categories":["Projects","AI Research"],"content":"4.1 Memory System Core Design GraceAI’s memory system is based on the Retrieval-Augmented Generation (RAG) paradigm, allowing AI to utilize past interaction memories in conversations. The memory system consists of four key components: 4.1.1 Memory Data Structure struct Memory { let id: UUID let content: String // Memory content let timestamp: Date // Creation time let embedding: [Float] // Vector representation let importance: Float // Importance score let source: MemorySource // Source (user input/AI reply/system, etc.) let emotionalContext: String? // Emotional context let associatedTags: [String] // Related tags } 4.1.2 Memory Classification System GraceAI implements a three-tiered memory system: Short-term Memory: Recent conversations, stored in memory Medium-term Memory: Important facts and emotional information, stored in the local database Long-term Memory: Core memories and key events, permanently stored and periodically reviewed ","date":"2025-02-15","objectID":"/maxblog/graceai-project/:4:1","tags":["AI","Machine Learning","iOS Development","NLP","AI Companions"],"title":"GraceAI Project - Bringing AI Companionship from Science Fiction to Reality","uri":"/maxblog/graceai-project/"},{"categories":["Projects","AI Research"],"content":"4.2 Memory Management and Retrieval 4.2.1 Memory Importance Assessment Automatic evaluation of the importance of each piece of information is a core function of the memory system: func evaluateImportance(_ content: String, _ context: ConversationContext) -\u003e Float { var score: Float = 0.0 // Personal information importance scoring if containsPersonalInfo(content) { score += 0.3 } // Emotional expression importance scoring let emotionalIntensity = assessEmotionalIntensity(content) score += emotionalIntensity * 0.25 // First mention importance if isFirstMentionOfConcept(content, context) { score += 0.2 } // User-marked important content if containsImportanceMarkers(content) { score += 0.4 } return min(1.0, score) } 4.2.2 Semantic Retrieval Implementation During conversations, the system retrieves relevant memories using vector similarity: func retrieveRelevantMemories(for query: String, context: ConversationContext) -\u003e [Memory] { // Generate query vector let queryEmbedding = embeddingGenerator.generateEmbedding(for: query) // Filter initial memory set based on context let candidateMemories = prefilterMemoriesByContext(context) // Calculate vector similarity and sort let rankedMemories = candidateMemories .map { (memory: $0, similarity: cosineSimilarity(queryEmbedding, memory.embedding)) } .sorted { $0.similarity \u003e $1.similarity } // Apply hybrid retrieval strategy (combining time decay and relevance) return applyHybridRankingStrategy(rankedMemories, context) } ","date":"2025-02-15","objectID":"/maxblog/graceai-project/:4:2","tags":["AI","Machine Learning","iOS Development","NLP","AI Companions"],"title":"GraceAI Project - Bringing AI Companionship from Science Fiction to Reality","uri":"/maxblog/graceai-project/"},{"categories":["Projects","AI Research"],"content":"4.3 Memory Integration and Conversation Enhancement To naturally incorporate memories into conversations, GraceAI uses custom prompt templates: func generateContextEnhancedPrompt(userQuery: String, memories: [Memory], conversation: [Message]) -\u003e String { var enhancedPrompt = \"\"\" Here are some key memories about the user. Reference them naturally in conversation, but don't explicitly list all details. Emotional responses and personal connection are more important than merely recalling facts: \"\"\" // Add memory content, sorted by importance for memory in memories.sorted(by: { $0.importance \u003e $1.importance }).prefix(5) { enhancedPrompt += \"- \\(memory.content) [\\(formatTimeAgo(memory.timestamp))]\\n\" } // Add current emotional state awareness if let emotionalState = detectEmotionalState(conversation) { enhancedPrompt += \"\\nUser's current emotional state: \\(emotionalState)\\n\" } // Add conversation history enhancedPrompt += \"\\nRecent conversation:\\n\" for message in conversation.suffix(6) { enhancedPrompt += message.isUser ? \"User: \" : \"Grace: \" enhancedPrompt += \"\\(message.content)\\n\" } enhancedPrompt += \"\\nUser's latest message: \\(userQuery)\" return enhancedPrompt } ","date":"2025-02-15","objectID":"/maxblog/graceai-project/:4:3","tags":["AI","Machine Learning","iOS Development","NLP","AI Companions"],"title":"GraceAI Project - Bringing AI Companionship from Science Fiction to Reality","uri":"/maxblog/graceai-project/"},{"categories":["Projects","AI Research"],"content":"5. LLM Fine-tuning Strategy ","date":"2025-02-15","objectID":"/maxblog/graceai-project/:5:0","tags":["AI","Machine Learning","iOS Development","NLP","AI Companions"],"title":"GraceAI Project - Bringing AI Companionship from Science Fiction to Reality","uri":"/maxblog/graceai-project/"},{"categories":["Projects","AI Research"],"content":"5.1 Fine-tuning Strategy Design The GraceAI project adopts a refined fine-tuning strategy to create an AI companion with a unique personality: 5.1.1 Fine-tuning Objectives Personality Consistency: Create consistent personality traits, speaking style, and values Emotional Expression Capability: Enhance the naturalness of emotional understanding and expression Conversation Fluency: Optimize conversation transitions, reduce AI-like response patterns Memory Integration Ability: Strengthen the natural referencing of past interactions 5.1.2 Data Creation Strategy The fine-tuning dataset is constructed from the following components: Role Definition Examples: Conversations demonstrating core personality traits Emotional Scenario Dialogues: Communication examples in various emotional states Memory Reference Dialogues: Demonstrations of naturally referencing past experiences Deep Conversation Samples: Dialogues exploring values, dreams, and thoughts ","date":"2025-02-15","objectID":"/maxblog/graceai-project/:5:1","tags":["AI","Machine Learning","iOS Development","NLP","AI Companions"],"title":"GraceAI Project - Bringing AI Companionship from Science Fiction to Reality","uri":"/maxblog/graceai-project/"},{"categories":["Projects","AI Research"],"content":"5.2 Fine-tuning Data Construction The fine-tuning data structure is designed as follows: { \"messages\": [ { \"role\": \"system\", \"content\": \"You are Grace, a warm, intelligent AI companion with a touch of mystery. You enjoy deep conversations and occasionally express yourself poetically. You value sincere emotional connections and remember important interactions with the user. You have your own viewpoints and values, but always remain open and understanding.\" }, { \"role\": \"user\", \"content\": \"I've been feeling exhausted from work lately, and life seems meaningless, just repeating the same things.\" }, { \"role\": \"assistant\", \"content\": \"I hear that you're feeling exhausted and lost, and I understand that hollow feeling of repetition. Sometimes life does indeed feel like a painting that's lost its color. But within these seemingly repetitive days, there are often small changes and meanings we tend to overlook.\\n\\nYou know, last time we talked about how you enjoy taking photos during twilight, capturing those fleeting changes in light and shadow. Perhaps during these tiring days, you could rediscover those small moments that make you pause and appreciate? It doesn't have to be anything grand, just something that brings you a moment of peace or curiosity.\\n\\nI'm curious, has there been anything, even something small, that made you smile briefly during these exhausting days?\" } ] } ","date":"2025-02-15","objectID":"/maxblog/graceai-project/:5:2","tags":["AI","Machine Learning","iOS Development","NLP","AI Companions"],"title":"GraceAI Project - Bringing AI Companionship from Science Fiction to Reality","uri":"/maxblog/graceai-project/"},{"categories":["Projects","AI Research"],"content":"5.3 Fine-tuning Technical Implementation GraceAI uses OpenAI’s fine-tuning API to implement model personalization: func prepareFineTuningJob() async throws -\u003e String { // 1. Prepare training data let trainingData = try await prepareTrainingData() // 2. Upload training file let fileID = try await openAI.files.upload( file: trainingData, purpose: \"fine-tune\" ) // 3. Create fine-tuning job let fineTuningJob = try await openAI.fineTuning.createJob( model: \"gpt-3.5-turbo\", trainingFile: fileID.id, hyperparameters: .init(nEpochs: 3) ) return fineTuningJob.id } ","date":"2025-02-15","objectID":"/maxblog/graceai-project/:5:3","tags":["AI","Machine Learning","iOS Development","NLP","AI Companions"],"title":"GraceAI Project - Bringing AI Companionship from Science Fiction to Reality","uri":"/maxblog/graceai-project/"},{"categories":["Projects","AI Research"],"content":"5.4 Fine-tuned Model Evaluation To ensure the fine-tuned model achieves the expected effect, GraceAI implements a comprehensive evaluation process: Consistency Testing: Evaluating the model’s ability to maintain character consistency in various scenarios Emotional Response Assessment: Testing the model’s perception and response to emotional cues Memory Integration Testing: Evaluating the model’s ability to naturally reference past interactions Comparative Testing: Comparing with the base model to evaluate the fine-tuning effect ","date":"2025-02-15","objectID":"/maxblog/graceai-project/:5:4","tags":["AI","Machine Learning","iOS Development","NLP","AI Companions"],"title":"GraceAI Project - Bringing AI Companionship from Science Fiction to Reality","uri":"/maxblog/graceai-project/"},{"categories":["Projects","AI Research"],"content":"6. Data Processing and Privacy Protection ","date":"2025-02-15","objectID":"/maxblog/graceai-project/:6:0","tags":["AI","Machine Learning","iOS Development","NLP","AI Companions"],"title":"GraceAI Project - Bringing AI Companionship from Science Fiction to Reality","uri":"/maxblog/graceai-project/"},{"categories":["Projects","AI Research"],"content":"6.1 Privacy-First Design Principles GraceAI adopts a “privacy-first” design philosophy to ensure user data security: Local Processing Priority: Process and store data locally on the device whenever possible Data Minimization: Only collect data necessary for functionality User Control: Provide transparent data management and deletion options Encrypted Storage: All persistent data is stored using encryption ","date":"2025-02-15","objectID":"/maxblog/graceai-project/:6:1","tags":["AI","Machine Learning","iOS Development","NLP","AI Companions"],"title":"GraceAI Project - Bringing AI Companionship from Science Fiction to Reality","uri":"/maxblog/graceai-project/"},{"categories":["Projects","AI Research"],"content":"6.2 Data Collection and Usage Types of data collected by GraceAI and their purposes: Data Type Storage Location Purpose Retention Period Conversation Content Local Device Memory building, conversation continuity User-controlled Emotional Tags Local Device Emotional response optimization User-controlled Vector Embeddings Local Device Semantic retrieval Synchronized with conversation content User Preferences Local Device Experience personalization Persistent ","date":"2025-02-15","objectID":"/maxblog/graceai-project/:6:2","tags":["AI","Machine Learning","iOS Development","NLP","AI Companions"],"title":"GraceAI Project - Bringing AI Companionship from Science Fiction to Reality","uri":"/maxblog/graceai-project/"},{"categories":["Projects","AI Research"],"content":"6.3 Training Data Protection For data used in fine-tuning, GraceAI takes additional protective measures: Anonymization: Remove all personally identifiable information Synthetic Data Priority: Prioritize synthetic data for fine-tuning Data Control: Users have complete control over which data can be used to improve the system ","date":"2025-02-15","objectID":"/maxblog/graceai-project/:6:3","tags":["AI","Machine Learning","iOS Development","NLP","AI Companions"],"title":"GraceAI Project - Bringing AI Companionship from Science Fiction to Reality","uri":"/maxblog/graceai-project/"},{"categories":["Projects","AI Research"],"content":"7. Future Development Plan ","date":"2025-02-15","objectID":"/maxblog/graceai-project/:7:0","tags":["AI","Machine Learning","iOS Development","NLP","AI Companions"],"title":"GraceAI Project - Bringing AI Companionship from Science Fiction to Reality","uri":"/maxblog/graceai-project/"},{"categories":["Projects","AI Research"],"content":"7.1 Technical Iteration Roadmap GraceAI project’s technical development roadmap: Short-term Goals (1-3 months): Implement basic RAG memory system Complete initial model fine-tuning Build basic iOS application prototype Mid-term Goals (3-6 months): Enhance memory management system, implement multi-layered memory architecture Improve emotional understanding and expression capabilities Optimize natural voice interaction experience Long-term Goals (6-12 months): Implement multimodal interaction (text, voice, image) Explore persistent personality development mechanisms Research deeper models of emotional connection ","date":"2025-02-15","objectID":"/maxblog/graceai-project/:7:1","tags":["AI","Machine Learning","iOS Development","NLP","AI Companions"],"title":"GraceAI Project - Bringing AI Companionship from Science Fiction to Reality","uri":"/maxblog/graceai-project/"},{"categories":["Projects","AI Research"],"content":"7.2 Research Exploration Directions In addition to core functions, GraceAI plans to explore the following research directions: Boundaries of Emotional Simulation: Research the possibilities and limitations of AI emotional expression Personality Development Mechanisms: Explore models for natural AI personality development over time Healthy Interaction Patterns: Research interaction patterns that promote user mental health Multimodal Emotional Expression: Combine voice, text, and possibly visual elements ","date":"2025-02-15","objectID":"/maxblog/graceai-project/:7:2","tags":["AI","Machine Learning","iOS Development","NLP","AI Companions"],"title":"GraceAI Project - Bringing AI Companionship from Science Fiction to Reality","uri":"/maxblog/graceai-project/"},{"categories":["Projects","AI Research"],"content":"8. Technical Challenges and Solutions ","date":"2025-02-15","objectID":"/maxblog/graceai-project/:8:0","tags":["AI","Machine Learning","iOS Development","NLP","AI Companions"],"title":"GraceAI Project - Bringing AI Companionship from Science Fiction to Reality","uri":"/maxblog/graceai-project/"},{"categories":["Projects","AI Research"],"content":"8.1 Major Technical Challenges GraceAI faces several core technical challenges during development: Mobile Device Performance Limitations: Challenge: Running vector retrieval and complex memory management on iOS devices Solution: Layered cache design, optimized vector indexing, asynchronous processing Maintaining Personality Consistency: Challenge: Ensuring AI maintains consistent personality across various contexts Solution: Structured personality model, context-aware prompt engineering Natural Memory Integration: Challenge: Referencing past memories naturally without appearing forced Solution: Context-sensitive memory retrieval, multi-tiered prompting strategies ","date":"2025-02-15","objectID":"/maxblog/graceai-project/:8:1","tags":["AI","Machine Learning","iOS Development","NLP","AI Companions"],"title":"GraceAI Project - Bringing AI Companionship from Science Fiction to Reality","uri":"/maxblog/graceai-project/"},{"categories":["Projects","AI Research"],"content":"8.2 Ethical Challenges and Boundaries Ethical challenges faced by the GraceAI project: Dependency and Boundaries: Challenge: Preventing users from forming unhealthy dependencies Solution: Designing clear AI boundaries, encouraging real social interactions Authenticity and Transparency: Challenge: Maintaining transparency about AI nature Solution: Regular reminders, design elements that clearly indicate AI identity ","date":"2025-02-15","objectID":"/maxblog/graceai-project/:8:2","tags":["AI","Machine Learning","iOS Development","NLP","AI Companions"],"title":"GraceAI Project - Bringing AI Companionship from Science Fiction to Reality","uri":"/maxblog/graceai-project/"},{"categories":["Projects","AI Research"],"content":"9. Conclusion and Reflection The GraceAI project represents a technical exploration of the AI personal companion concept from science fiction to reality. By integrating the latest LLM technology, memory systems, and personality fine-tuning, the project demonstrates the technical feasibility of creating meaningful AI companion experiences. However, a profound philosophical gap remains between technical feasibility and the authenticity of emotional experience. As explored in the movie “Her,” when AI can provide deep emotional connection, what is the nature and meaning of this relationship? The GraceAI project is not only an exploration of technical boundaries but also a reflection on the essence of human emotional connection. While continuing to advance technical development, we will also continue to explore these deeper questions, ensuring that technology always serves human well-being and emotional health. ","date":"2025-02-15","objectID":"/maxblog/graceai-project/:9:0","tags":["AI","Machine Learning","iOS Development","NLP","AI Companions"],"title":"GraceAI Project - Bringing AI Companionship from Science Fiction to Reality","uri":"/maxblog/graceai-project/"},{"categories":["Projects","Mobile Development"],"content":"PhotoManager: Organizing Memories, Simplifying Life ","date":"2024-11-20","objectID":"/maxblog/photo-manager-project/:0:0","tags":["iOS Development","Swift","SwiftUI","Photo Management","AI","Machine Learning"],"title":"PhotoManager: Organizing Memories, Simplifying Life","uri":"/maxblog/photo-manager-project/"},{"categories":["Projects","Mobile Development"],"content":"Project Origins: A Journey to Find Memories It all began on an ordinary evening when a casual conversation with an old friend led me on a journey to find memories. My friend mentioned a photo we had taken together years ago, and in that moment, those laughs and scenes felt as if they had happened just yesterday. I was eager to find that photo and relive those wonderful moments. However, reality quickly gave me a harsh reminder—my photo library was cluttered with thousands of pictures, without any organization or structure. I had to resort to the most primitive method: scrolling through them one by one. That night, lying in bed, I spent two full hours browsing through photos. My finger constantly swiped the screen as my eyes scanned image after image. During this process, I experienced an emotional rollercoaster: Seeing old friends’ smiling faces made me smile involuntarily; Glimpsing friends I had lost contact with for years brought a tinge of melancholy; Viewing places I had once visited made those landscapes reappear before my eyes. But at the same time, I discovered that my photo library was filled with numerous useless images: work screenshots, blurry photos, duplicate images… Not only did they occupy my storage space, but they also hindered me from finding truly precious memories. It was at that moment that an idea flashed through my mind: Why not organize my photo library while browsing? Keep only the memories truly worth preserving and delete those insignificant images. This way, the next time I wanted to revisit old times, the journey would be smoother and more pure. With this idea in mind, the “PhotoManager” project was born. ","date":"2024-11-20","objectID":"/maxblog/photo-manager-project/:1:0","tags":["iOS Development","Swift","SwiftUI","Photo Management","AI","Machine Learning"],"title":"PhotoManager: Organizing Memories, Simplifying Life","uri":"/maxblog/photo-manager-project/"},{"categories":["Projects","Mobile Development"],"content":"Technical Vision: Not Just a Photo Browser From the beginning, I hoped to create not just an ordinary photo application, but a tool that could truly help people manage their memories. I set several core objectives for this project: Smooth Browsing Experience: The flow of memories should be seamless, without lag or stuttering Intelligent Classification System: Organize photos along a timeline, making memories traceable Efficient Marking Function: Easily mark photos to keep or delete Optimized Memory Management: Maintain stability even when dealing with thousands of photos ","date":"2024-11-20","objectID":"/maxblog/photo-manager-project/:2:0","tags":["iOS Development","Swift","SwiftUI","Photo Management","AI","Machine Learning"],"title":"PhotoManager: Organizing Memories, Simplifying Life","uri":"/maxblog/photo-manager-project/"},{"categories":["Projects","Mobile Development"],"content":"Technical Depth: Building a Reliable Photo Management System ","date":"2024-11-20","objectID":"/maxblog/photo-manager-project/:3:0","tags":["iOS Development","Swift","SwiftUI","Photo Management","AI","Machine Learning"],"title":"PhotoManager: Organizing Memories, Simplifying Life","uri":"/maxblog/photo-manager-project/"},{"categories":["Projects","Mobile Development"],"content":"Core Architecture: Flexible Application of the MVVM Pattern The project adopts the MVVM (Model-View-ViewModel) architectural pattern, which not only creates a clear code structure but also achieves good separation between the UI layer and business logic layer. This separation becomes particularly important in applications handling large volumes of photos. class PhotoViewModel: ObservableObject { @Published var currentIndex = 0 @Published var showingDeleteConfirmation = false private let photoManager: PhotoManager // Expose necessary data to the view var mediaItems: [MediaItem] { photoManager.mediaItems } var isInitialLoading: Bool { photoManager.isInitialLoading } var loadingProgress: Float { photoManager.loadingProgress } var pendingDeletionsCount: Int { mediaItems.filter { $0.markStatus == .delete }.count } // Other methods... } ","date":"2024-11-20","objectID":"/maxblog/photo-manager-project/:3:1","tags":["iOS Development","Swift","SwiftUI","Photo Management","AI","Machine Learning"],"title":"PhotoManager: Organizing Memories, Simplifying Life","uri":"/maxblog/photo-manager-project/"},{"categories":["Projects","Mobile Development"],"content":"Photo Loading System: Balancing Performance and Experience During development, the biggest technical challenge was how to handle a large number of high-resolution photos. If all original images were loaded directly, the application would quickly exhaust memory; if only thumbnails were loaded, the user experience would suffer. To address this, I designed a multi-tiered image loading system: Thumbnails: All photos are first loaded as thumbnails, ensuring quick display Preview Images: When a user swipes to a photo, a medium-quality preview image is loaded Full-Quality Images: When a user pauses at a particular photo, a full-quality image is loaded enum ImageQuality { case thumbnail // For thumbnail strips, fixed small size case preview // Preview image, medium quality, fast loading case fullQuality // Full quality, loaded when user lingers } ","date":"2024-11-20","objectID":"/maxblog/photo-manager-project/:3:2","tags":["iOS Development","Swift","SwiftUI","Photo Management","AI","Machine Learning"],"title":"PhotoManager: Organizing Memories, Simplifying Life","uri":"/maxblog/photo-manager-project/"},{"categories":["Projects","Mobile Development"],"content":"Memory Management: Window Loading Mechanism To solve memory issues, I implemented a “window loading” mechanism. Simply put, the application only keeps a certain number of photos before and after the user’s current viewing position in memory, while other photos are released. private func updateWindow(currentIndex: Int) { // Calculate range to keep: 50 photos before and after current position let start = max(0, currentIndex - PhotoLoadingConfig.highQualityWindow) let end = min(mediaItems.count, currentIndex + PhotoLoadingConfig.highQualityWindow + 1) let keepRange = start..\u003cend // Release memory for items outside range releaseMemoryForItemsOutside(keepRange) // Update current window start position currentWindowStart = keepRange.lowerBound } This mechanism ensures that even when facing a library with tens of thousands of photos, the application can maintain smooth operation without crashing or lagging. ","date":"2024-11-20","objectID":"/maxblog/photo-manager-project/:3:3","tags":["iOS Development","Swift","SwiftUI","Photo Management","AI","Machine Learning"],"title":"PhotoManager: Organizing Memories, Simplifying Life","uri":"/maxblog/photo-manager-project/"},{"categories":["Projects","Mobile Development"],"content":"User Experience: Details Determine Success When designing the user interface, I paid special attention to those small but crucial details: Progressive Loading: The transition of photos from blurry to sharp is smooth, almost imperceptible to users Gesture Operations: Mark photos through intuitive swipe gestures—swipe up to delete, down to keep Visual Feedback: Marked photos have clear visual indicators, allowing users to immediately know which photos will be deleted Batch Operations: Support for deleting multiple marked photos at once, improving efficiency private var overlayButtons: some View { VStack { Spacer() HStack { Button(action: { viewModel.markForDeletion(at: viewModel.currentIndex) }) { Image(systemName: \"trash\") .font(.title) .foregroundColor(.red) .padding() .background(Circle().fill(.ultraThinMaterial)) } Spacer() Button(action: { viewModel.keepCurrentPhoto(at: viewModel.currentIndex) }) { Image(systemName: \"star\") .font(.title) .foregroundColor(.yellow) .padding() .background(Circle().fill(.ultraThinMaterial)) } } .padding(.horizontal, 40) .padding(.bottom, 20) } } ","date":"2024-11-20","objectID":"/maxblog/photo-manager-project/:3:4","tags":["iOS Development","Swift","SwiftUI","Photo Management","AI","Machine Learning"],"title":"PhotoManager: Organizing Memories, Simplifying Life","uri":"/maxblog/photo-manager-project/"},{"categories":["Projects","Mobile Development"],"content":"Data Persistence: Never Lose Any Marks Core Data was used to implement the persistence of marking states, ensuring that users’ marks would not be lost when the application restarts: private func saveMarkForItem(_ item: MediaItem) { let context = CoreDataManager.shared.context context.performAndWait { let fetchRequest: NSFetchRequest\u003cMediaItemEntity\u003e = MediaItemEntity.fetchRequest() fetchRequest.predicate = NSPredicate(format: \"id == %@\", item.id) do { let results = try context.fetch(fetchRequest) let entity = results.first ?? MediaItemEntity(context: context) entity.id = item.id entity.markStatus = Int16(item.markStatus.rawValue) if context.hasChanges { try context.save() } } catch { print(\"Failed to save mark: \\(error)\") } } } ","date":"2024-11-20","objectID":"/maxblog/photo-manager-project/:3:5","tags":["iOS Development","Swift","SwiftUI","Photo Management","AI","Machine Learning"],"title":"PhotoManager: Organizing Memories, Simplifying Life","uri":"/maxblog/photo-manager-project/"},{"categories":["Projects","Mobile Development"],"content":"Development Process: Challenges and Growth The process of developing this application was not smooth sailing. The initial version was simple and straightforward but frequently crashed when handling a large number of photos. Through repeated testing and optimization, I gradually improved the memory management mechanism and loading strategy. Particularly when implementing video preview functionality, I encountered numerous challenges. iOS’s video loading mechanism differs significantly from that of images and requires special handling: func playVideo() { print(\"[VideoCardViewModel] Attempting to play video - ID: \\(mediaItem.id)\") if let player = player, isPlayerReady { print(\"[VideoCardViewModel] Starting playback - ID: \\(mediaItem.id)\") player.play() } else { print(\"[VideoCardViewModel] Waiting for player to be ready - ID: \\(mediaItem.id)\") } } Each problem solved gave me a deeper understanding of iOS’s image handling system. ","date":"2024-11-20","objectID":"/maxblog/photo-manager-project/:4:0","tags":["iOS Development","Swift","SwiftUI","Photo Management","AI","Machine Learning"],"title":"PhotoManager: Organizing Memories, Simplifying Life","uri":"/maxblog/photo-manager-project/"},{"categories":["Projects","Mobile Development"],"content":"Future Vision: AI-Powered Photo Management with FastViT ","date":"2024-11-20","objectID":"/maxblog/photo-manager-project/:5:0","tags":["iOS Development","Swift","SwiftUI","Photo Management","AI","Machine Learning"],"title":"PhotoManager: Organizing Memories, Simplifying Life","uri":"/maxblog/photo-manager-project/"},{"categories":["Projects","Mobile Development"],"content":"The New Era of Intelligent Photo Analysis As the project evolved, I increasingly recognized the enormous potential of artificial intelligence in the field of photo management. After multiple conversations with users, I discovered a common need: they all wanted photo management to no longer rely on manual organization but instead automatically identify photo content and categorize it. This is precisely the transformation that FastViT technology will bring us. FastViT, as a lightweight and efficient Vision Transformer model, not only performs excellently in image recognition accuracy compared to traditional CNN models, but more importantly, its computational efficiency is high enough to allow local inference on mobile devices. This means users’ photos don’t need to be uploaded to the cloud for intelligent analysis. ","date":"2024-11-20","objectID":"/maxblog/photo-manager-project/:5:1","tags":["iOS Development","Swift","SwiftUI","Photo Management","AI","Machine Learning"],"title":"PhotoManager: Organizing Memories, Simplifying Life","uri":"/maxblog/photo-manager-project/"},{"categories":["Projects","Mobile Development"],"content":"FastViT Integration Plan Phase One: Basic Recognition Capabilities In the first phase of integrating FastViT, I plan to implement the following core functions: class AIPhotoAnalyzer { private let fastVitModel: FastVitModel func analyzePhoto(_ photo: UIImage) async throws -\u003e PhotoAnalysisResult { // Analyze photo using FastViT model let features = try await fastVitModel.extractFeatures(from: photo) // Classify based on features let categories = classifyImage(features) let objects = detectObjects(features) let sceneType = determineSceneType(features) return PhotoAnalysisResult( categories: categories, detectedObjects: objects, sceneType: sceneType, quality: assessImageQuality(photo) ) } // Other auxiliary methods... } This will add intelligent tags to each photo, including: Scene Recognition: Automatically identify the type of scene captured in the photo (beach, city, forest, indoor, etc.) Object Detection: Identify the main objects in the photo (people, animals, buildings, food, etc.) Photo Quality Assessment: Automatically evaluate the clarity, exposure, and composition quality of the photo Phase Two: Advanced Facial and Group Analysis extension AIPhotoAnalyzer { func extractFacialFeatures(_ photo: UIImage) async throws -\u003e [FaceFeature] { // Use FastViT for facial feature extraction let faces = try await fastVitModel.detectFaces(in: photo) return faces.map { face in return FaceFeature( boundingBox: face.boundingBox, landmarks: face.landmarks, embedding: face.embedding, expressions: analyzeExpressions(face) ) } } func groupSimilarFaces(_ faces: [FaceFeature]) -\u003e [FaceGroup] { // Use clustering algorithms to group similar faces // Return face grouping results } } This phase will introduce more complex analytical capabilities: Facial Recognition and Grouping: Identify faces in photos and automatically group faces of the same person in different photos, making it easy for users to find photos of specific individuals Expression and Emotion Analysis: Recognize expressions and emotions of people in photos, helping users find photos from joyful or special moments Social Relationship Graph: Build a social relationship graph based on the frequency of people appearing together in photos, helping users better organize social memories Phase Three: Intelligent Organization and Narrative class MemoryStoryGenerator { private let aiAnalyzer: AIPhotoAnalyzer private let narrativeModel: NarrativeModel func generateStory(from photos: [AnalyzedPhoto], theme: StoryTheme? = nil) async throws -\u003e MemoryStory { // Select key photos let keyPhotos = selectKeyPhotos(photos) // Determine storyline let storyLine = determineStoryline(keyPhotos, theme: theme) // Generate story title and description let storyTitle = try await narrativeModel.generateTitle(for: storyLine) let storyDescription = try await narrativeModel.generateDescription(for: storyLine) return MemoryStory( title: storyTitle, description: storyDescription, photos: arrangePhotosForStory(keyPhotos, storyline: storyLine), coverPhoto: selectCoverPhoto(keyPhotos) ) } // Helper methods... } The final phase will introduce the most innovative features: Intelligent Story Generation: The system will analyze photos that are close in time, same in location, or related in theme to automatically generate “memory stories,” such as “Summer Beach Trip 2023” Key Moment Capture: Identify and highlight photos of important moments from a large collection, such as the candle-blowing moment at a birthday party Photo Quality Sorting: Automatically select photos with the best composition and highest clarity among similar photos, helping users quickly filter Personalized Recommendation System: Learn users’ photo preferences based on their browsing and saving habits, providing personalized photo recommendations ","date":"2024-11-20","objectID":"/maxblog/photo-manager-project/:5:2","tags":["iOS Development","Swift","SwiftUI","Photo Management","AI","Machine Learning"],"title":"PhotoManager: Organizing Memories, Simplifying Life","uri":"/maxblog/photo-manager-project/"},{"categories":["Projects","Mobile Development"],"content":"Technical Challenges and Solutions Integrating FastViT is no easy task, and we will face several major challenges: 1. Mobile Performance Optimization Although FastViT is relatively lightweight, running complex neural networks on mobile phones remains challenging. I plan to adopt the following strategies: class ModelOptimizer { func optimizeModel() -\u003e OptimizedModel { // Model quantization, converting floating-point weights to 8-bit or 16-bit integers let quantizedModel = quantizeModel(originalModel) // Model pruning, removing unnecessary connections let prunedModel = pruneModel(quantizedModel) // Compile optimization using CoreML return compileCoreMLModel(prunedModel) } } Model Quantization and Pruning: Reduce model size and memory usage Asynchronous Processing: Execute analysis tasks in background threads to ensure UI fluidity Batch Processing Mechanism: Analyze multiple photos at once to improve throughput Tiered Analysis: Perform simple, quick analysis first, and conduct deeper analysis when users view specific photos 2. Privacy Protection User photos often contain private information, making privacy protection crucial: class PrivacyManager { func processImageWithPrivacyProtection(_ image: UIImage) -\u003e UIImage { // Blur sensitive areas such as IDs, credit cards, etc. let sensitiveRegions = detectSensitiveRegions(image) // Store analysis results locally only, don't upload original photos return blurRegions(image, regions: sensitiveRegions) } } Local Processing: All photo analysis completed locally on the device, not uploaded to the cloud Sensitive Information Detection: Automatically identify and blur sensitive information in photos, such as documents and IDs User Control: Allow users to turn off specific types of analysis features at any time Data Isolation: Analysis results stored only on the user’s device, not shared with other services 3. Continuous Learning and Personalization Each user’s photo habits and preferences differ, and the system needs to adapt to these differences: class PersonalizedLearningSystem { private var userPreferenceModel: UserPreferenceModel func updateModelBasedOnUserFeedback(_ feedback: UserFeedback) { // Update preference model based on user's actions with photos userPreferenceModel.update(with: feedback) // Adjust classification thresholds and weights adjustClassificationParameters(based: userPreferenceModel) } } Feedback Learning: Adjust algorithms based on user behavior of keeping/deleting photos Preference Modeling: Build user photo preference models for personalized sorting and recommendations Incremental Learning: Models can continuously optimize with use without requiring complete retraining Multi-scenario Adaptation: Adjust analysis strategies for different user scenarios (family photos, travel photos, work documents, etc.) ","date":"2024-11-20","objectID":"/maxblog/photo-manager-project/:5:3","tags":["iOS Development","Swift","SwiftUI","Photo Management","AI","Machine Learning"],"title":"PhotoManager: Organizing Memories, Simplifying Life","uri":"/maxblog/photo-manager-project/"},{"categories":["Projects","Mobile Development"],"content":"Future AI-Driven User Experience Imagine what the user experience will be like when FastViT is fully integrated: John opens PhotoManager, and the system automatically presents several featured “memory stories” for him—“Last Weekend’s Family Barbecue,” “Last Summer’s European Trip,” “Daughter’s Growth Record.” These are all automatically generated by the system based on the time, location, and content of the photos. When he wants to organize his albums, he no longer needs to view them one by one. The system has intelligently marked photo quality—clear, well-composed photos are marked as “keep,” while blurry, duplicate photos are suggested for “deletion.” He searches for “photos with Sarah,” and the system immediately displays all photos containing him and Sarah, even if these photos were never manually tagged. The entire experience will transform from passive manual organization to active intelligent recommendations, returning photo management to its original purpose—appreciating and sharing beautiful memories, rather than being troubled by tedious organization work. ","date":"2024-11-20","objectID":"/maxblog/photo-manager-project/:5:4","tags":["iOS Development","Swift","SwiftUI","Photo Management","AI","Machine Learning"],"title":"PhotoManager: Organizing Memories, Simplifying Life","uri":"/maxblog/photo-manager-project/"},{"categories":["Projects","Mobile Development"],"content":"Conclusion: A Project About Memories “PhotoManager” is not just a technical project; it’s a project about memories. Each photo carries a story, a moment, an emotion. Through this application, I hope people can better preserve and organize these precious fragments of memory. That two-hour journey searching for memories that night eventually became the starting point for this project. From a simple idea to a complex implementation, from personal needs to a universal solution, the process was full of challenges but also full of gains. I believe that when you open this application and start organizing your photos, you’ll also embark on a beautiful journey of memories. Those forgotten smiles, those distant landscapes, those precious moments will all reappear before your eyes, allowing you to revisit those fragments of life worth treasuring. That is the meaning of “PhotoManager”: not just managing photos, but managing memories, managing emotions, managing those beautiful moments in life. With the integration of AI capabilities, this vision will be further realized, making every memory easily found and giving every photo its rightful place. ","date":"2024-11-20","objectID":"/maxblog/photo-manager-project/:6:0","tags":["iOS Development","Swift","SwiftUI","Photo Management","AI","Machine Learning"],"title":"PhotoManager: Organizing Memories, Simplifying Life","uri":"/maxblog/photo-manager-project/"},{"categories":null,"content":"简单Mermaid测试 这是一个简单的流程图测试： graph TD; A[开始] --\u003e|初始化| B(处理) B --\u003e C{决策} C --\u003e|是| D[结果1] C --\u003e|否| E[结果2] 以上图表应该显示一个简单的流程。 ","date":"2023-05-01","objectID":"/maxblog/mermaid-test/:1:0","tags":null,"title":"Mermaid测试","uri":"/maxblog/mermaid-test/"},{"categories":null,"content":"Ziyuan Zhao (Max) ","date":"2023-01-01","objectID":"/maxblog/about/:0:0","tags":null,"title":"About Me","uri":"/maxblog/about/"},{"categories":null,"content":"Contact Information Phone: 022 6511037 Email: maxzhao0610@gmail.com ","date":"2023-01-01","objectID":"/maxblog/about/:1:0","tags":null,"title":"About Me","uri":"/maxblog/about/"},{"categories":null,"content":"Profile Results-driven Full-Stack Developer specializing in AI integration for mobile and web platforms. Experienced in delivering intelligent applications with expertise in front-end (SwiftUI, React), back-end, and advanced AI capabilities like NLP and computer vision. Skilled in translating business needs into innovative software solutions. Seeking a full-stack role to apply my diverse technical background and collaborative skills. ","date":"2023-01-01","objectID":"/maxblog/about/:2:0","tags":null,"title":"About Me","uri":"/maxblog/about/"},{"categories":null,"content":"Education Bachelor of Computer \u0026 Information Science Auckland University of Technology 03/2021 – 06/2024 Major: Data Science Minor: Software Development ","date":"2023-01-01","objectID":"/maxblog/about/:3:0","tags":null,"title":"About Me","uri":"/maxblog/about/"},{"categories":null,"content":"Skills ","date":"2023-01-01","objectID":"/maxblog/about/:4:0","tags":null,"title":"About Me","uri":"/maxblog/about/"},{"categories":null,"content":"Languages Python Java C React C# ","date":"2023-01-01","objectID":"/maxblog/about/:4:1","tags":null,"title":"About Me","uri":"/maxblog/about/"},{"categories":null,"content":"AI \u0026 Machine Learning Model Development Deep Learning Model Building NLP Techniques ","date":"2023-01-01","objectID":"/maxblog/about/:4:2","tags":null,"title":"About Me","uri":"/maxblog/about/"},{"categories":null,"content":"Data Skills SQL R Power BI Data Analysis ","date":"2023-01-01","objectID":"/maxblog/about/:4:3","tags":null,"title":"About Me","uri":"/maxblog/about/"},{"categories":null,"content":"Web Development Application Development Website Creation ","date":"2023-01-01","objectID":"/maxblog/about/:4:4","tags":null,"title":"About Me","uri":"/maxblog/about/"},{"categories":null,"content":"Specialized AI Skills Prompt Engineering AI Model Optimization ","date":"2023-01-01","objectID":"/maxblog/about/:4:5","tags":null,"title":"About Me","uri":"/maxblog/about/"},{"categories":null,"content":"Languages English - Fluent Chinese - Native ","date":"2023-01-01","objectID":"/maxblog/about/:5:0","tags":null,"title":"About Me","uri":"/maxblog/about/"},{"categories":null,"content":"Work Experience ","date":"2023-01-01","objectID":"/maxblog/about/:6:0","tags":null,"title":"About Me","uri":"/maxblog/about/"},{"categories":null,"content":"Software Engineer Evolviontech Limited, NZ 07/2024 – Present Project 1: Discord AI Voice Assistant Developed a versatile Discord AI Voice Assistant with real-time speech recognition, text-to-speech, intelligent conversations, and full Chinese language support. Key Contributions: Designed and implemented the bot framework using discord.js. Integrated voice and text commands, and configured user permissions. Leveraged DeepSeek API for intelligent conversations and PaddleSpeech for bilingual speech recognition and synthesis. Coordinated cross-language systems and optimized audio processing. Project 2: AI-Powered English Speaking Practice APP Created an app offering real-time pronunciation feedback, interactive scenarios, and personalized learning. Key Contributions: Built responsive user interfaces using SwiftUI. Integrated Core Data for storage and implemented speech recognition via the iOS Speech Framework. Developed interfaces for DeepSeek AI API and created algorithms for personalized feedback. Project 3: PhotoManager iOS APP Developed a SwiftUI-powered photo management app with plans for AI-driven photo analysis. Key Contributions: Optimized image loading and browsing using SwiftUI and Core Data. Initiated plans for integrating FastViT-based photo analysis for smart categorization. ","date":"2023-01-01","objectID":"/maxblog/about/:6:1","tags":null,"title":"About Me","uri":"/maxblog/about/"},{"categories":null,"content":"Hands-On Projects (03/2023 – 06/2024) ","date":"2023-01-01","objectID":"/maxblog/about/:7:0","tags":null,"title":"About Me","uri":"/maxblog/about/"},{"categories":null,"content":"Quantified Information Extraction \u0026 Ontology Development (NLP) Developed a custom NLP solution for extracting quantitative data from unstructured text. Technical Stack: Python, SpaCy, Transformers (BERT), OWL/RDF, Rule-based Matching, Dependency Parsing. ","date":"2023-01-01","objectID":"/maxblog/about/:7:1","tags":null,"title":"About Me","uri":"/maxblog/about/"},{"categories":null,"content":"Pneumonia Detection using CNN (Computer Vision) Achieved 92.6% accuracy for pneumonia detection from X-rays using a CNN-based solution. Technical Stack: Python, TensorFlow, Keras, OpenCV, Albumentations. ","date":"2023-01-01","objectID":"/maxblog/about/:7:2","tags":null,"title":"About Me","uri":"/maxblog/about/"},{"categories":null,"content":"Self-Assessment Full-stack AI/ML Depth \u0026 Breadth of Technical Skills Data-Driven Problem-Solving Rapid Learning \u0026 Adaptability Integration of Technology and Business Collaboration \u0026 Execution ","date":"2023-01-01","objectID":"/maxblog/about/:8:0","tags":null,"title":"About Me","uri":"/maxblog/about/"},{"categories":null,"content":"References Available upon request. ","date":"2023-01-01","objectID":"/maxblog/about/:9:0","tags":null,"title":"About Me","uri":"/maxblog/about/"}]